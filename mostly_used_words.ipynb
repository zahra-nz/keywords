{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xic12WONeW8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpVWWa-oeRxQ"
      },
      "outputs": [],
      "source": [
        "!pip install PyPDF2\n",
        "!pip install spacy\n",
        "!python -m spacy download fr_core_news_sm\n",
        "\n",
        "\n",
        "import PyPDF2\n",
        "import spacy\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import sys\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk_stopwords = set(stopwords.words('french'))\n",
        "\n",
        "nlp = spacy.load(\"fr_core_news_sm\")\n",
        "\n",
        "extra_stopwords = {\"plus\", \"tout\", \"comme\", \"a\", \"aux\", \"ainsi\", \"alors\", \"après\", \"aucun\", \"aucune\",\n",
        "                   \"autre\", \"avant\", \"avec\", \"avoir\", \"ça\", \"car\", \"ce\", \"cela\", \"cette\", \"cet\", \"ces\",\n",
        "                   \"cette\", \"dans\", \"donc\", \"dont\", \"du\", \"elle\", \"en\", \"est\", \"et\", \"eux\", \"il\", \"ils\",\n",
        "                   \"je\", \"là\", \"la\", \"le\", \"les\", \"leur\", \"lui\", \"ma\", \"mais\", \"me\", \"même\", \"mes\",\n",
        "                   \"moi\", \"mon\", \"ne\", \"nos\", \"notre\", \"nous\", \"on\", \"ou\", \"où\", \"par\", \"pas\", \"pour\",\n",
        "                   \"quand\", \"que\", \"qui\", \"sa\", \"se\", \"ses\", \"si\", \"son\", \"sont\", \"sur\", \"ta\", \"te\",\n",
        "                   \"tes\", \"toi\", \"ton\", \"tous\", \"tout\", \"trop\", \"tu\", \"un\", \"une\", \"vos\", \"votre\",\n",
        "                   \"vous\", \"y\" , \"of\" , \"the\" , \"in\" , \"for\" , \"b\" , \"and\" , \"vol\" , \"e\" , \"r\" , \"f\" ,\n",
        "                   \"v\" , \"ser\" , \"loi\" , \"re\" , \"sie\" , \"don\" , \"mots\" , \"titre\" ,  \"article\", \"code\",\n",
        "                   \"art\", \"alinéa\", \"mots\", \"remplace\", \"etat\", \"État\",\n",
        "                   \"rédigé\", \"disposition\", \"titre\", \"ar\", \"décret\", \"ministre\", \"ii\",\n",
        "                   \"modifié\", \"président\", \"mentionnés\", \"présent\", \"articles\", \"cas\",\n",
        "                   \"modifie\", \"présente\", \"général\", \"représentant\", \"texte\" , \"ticle\"\n",
        "                    , \"genre\" , \"Conditions\" , \"Tacle\" , \"Charge\"\n",
        "                   }\n",
        "                   #\"disposition\" , \"ar\" , \"ministre\" , \"ii\" , \"modifie\" , \"cas\" , \"article\" , \"code\"\n",
        "\n",
        "\n",
        "french_stopwords = nltk_stopwords.union(extra_stopwords).union(nlp.Defaults.stop_words)\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"استخراج متن از PDF\"\"\"\n",
        "    text = \"\"\n",
        "    with open(pdf_path, \"rb\") as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text() + \" \"\n",
        "    return text\n",
        "\n",
        "def process_text(text, top_n):\n",
        "    \"\"\"پردازش متن: حذف stopwords و شمارش پرتکرارترین کلمات\"\"\"\n",
        "    doc = nlp(text.lower())\n",
        "    words = [token.text for token in doc if token.is_alpha]\n",
        "    filtered_words = [word for word in words if word not in french_stopwords]  # stopwords\n",
        "    word_frequencies = Counter(filtered_words)  # counting\n",
        "\n",
        "    return word_frequencies.most_common(top_n)  # return\n",
        "\n",
        "# upload file in Colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# full name\n",
        "pdf_path = list(uploaded.keys())[0]\n",
        "\n",
        "# how many top used words\n",
        "top_n = int(input(\"how many top used words do you want to see?\"))\n",
        "\n",
        "# processing file and showing the output\n",
        "text = extract_text_from_pdf(pdf_path)\n",
        "most_common_words = process_text(text, top_n)\n",
        "\n",
        "# show results\n",
        "print(\"\\nmost used words in this file:(after removing Stopwords):\")\n",
        "for word, freq in most_common_words:\n",
        "    print(f\"{word}: {freq}\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_word_distribution(word_counts):\n",
        "    # extract words and how many are them\n",
        "    words, counts = zip(*word_counts)\n",
        "\n",
        "    # bar chart\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.bar(words, counts, color='skyblue')\n",
        "    plt.xlabel('Words')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Top Words - Bar Chart')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "    # pie chart\n",
        "    plt.figure(figsize=(7, 7))\n",
        "    plt.pie(counts, labels=words, autopct='%1.1f%%', startangle=90)\n",
        "    plt.title('Top Words - Pie Chart')\n",
        "    plt.show()\n",
        "\n",
        "# show plts\n",
        "plot_word_distribution(most_common_words)\n"
      ]
    }
  ]
}